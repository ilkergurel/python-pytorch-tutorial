{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAN for image generation\n",
    "#https://www.youtube.com/watch?v=ABaZ_tecZ3U&list=PLWKjhJtqVAbm3T2Eq1_KgloC7ogdXxdRa&index=6\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tt\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Get the parent directory and enter files\n",
    "DATA_DIR = os.path.abspath(os.path.join(os.getcwd(), os.pardir)) + '\\\\data_source\\\\anime-faces-images'\n",
    "\n",
    "\n",
    "print(os.listdir(DATA_DIR +'\\\\images')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "batch_size = 64\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "\n",
    "train_ds = ImageFolder(DATA_DIR, transform=tt.Compose([\n",
    "    #tt.RandomHorizontalFlip(),\n",
    "    #tt.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    tt.Resize((image_size, image_size)),\n",
    "    tt.CenterCrop(image_size),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(*stats)\n",
    "]))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size,shuffle=True, num_workers=4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def denorm(img_tensors):\n",
    "    return img_tensors * stats[1][0] + stats[0][0]\n",
    "\n",
    "def show_images(images, nmax=64):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid(denorm(images.detach()[:nmax]),nrow=8).permute(1,2,0))\n",
    "\n",
    "def show_batch(dl,nmax=64):\n",
    "    for images, _ in dl:\n",
    "        show_images(images, nmax)\n",
    "        break\n",
    "\n",
    "show_batch(train_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilize GPU\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensors to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"Wrap a dataloader to move data to a device\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b,self.device)\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "    \n",
    "device = get_default_device()\n",
    "print(\"device: \", device)\n",
    "\n",
    "train_dl = DeviceDataLoader(train_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Mapping Network\n",
    "# ------------------------------\n",
    "class MappingNetwork(nn.Module):\n",
    "    def __init__(self, latent_dim, num_layers):\n",
    "        super(MappingNetwork, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(latent_dim, latent_dim))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "        self.mapping = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.mapping(z)\n",
    "\n",
    "# ------------------------------\n",
    "# Adaptive Instance Normalization (AdaIN)\n",
    "# ------------------------------\n",
    "def adain(x, style):\n",
    "    mean = x.mean(dim=[2, 3], keepdim=True)\n",
    "    std = x.std(dim=[2, 3], keepdim=True)\n",
    "    style_mean, style_std = style.chunk(2, dim=1)\n",
    "    style_mean = style_mean.unsqueeze(-1).unsqueeze(-1)\n",
    "    style_std = style_std.unsqueeze(-1).unsqueeze(-1)\n",
    "    return style_std * (x - mean) / (std + 1e-8) + style_mean\n",
    "\n",
    "# ------------------------------\n",
    "# StyleGAN Generator\n",
    "# ------------------------------\n",
    "class StyleGANGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_channels, base_channels):\n",
    "        super(StyleGANGenerator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Mapping Network\n",
    "        self.mapping = MappingNetwork(latent_dim, num_layers=8)\n",
    "\n",
    "        # Fixed starting input\n",
    "        self.constant_input = nn.Parameter(torch.randn(1, base_channels, 4, 4))\n",
    "\n",
    "        # Progressive layers\n",
    "        self.prog_blocks = nn.ModuleList([\n",
    "            GeneratorBlock(base_channels // (2**i), base_channels // (2**(i + 1)), latent_dim)\n",
    "            for i in range(4)  # 4x4 -> 8x8 -> 16x16 -> 32x32 -> 64x64\n",
    "        ])\n",
    "\n",
    "        # Final RGB conversion layer\n",
    "        self.to_rgb = nn.Conv2d(base_channels // (2**(4)), img_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        style = self.mapping(z)\n",
    "        x = self.constant_input.repeat(z.size(0), 1, 1, 1)  #creates batch number of constant_input\n",
    "\n",
    "        # Pass through progressive blocks\n",
    "        for block in self.prog_blocks:\n",
    "            x = block(x, style)\n",
    "\n",
    "        # Final RGB conversion\n",
    "        rgb = self.to_rgb(x)\n",
    "\n",
    "        return torch.tanh(rgb)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Generator Block\n",
    "# ------------------------------\n",
    "class GeneratorBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, style_dim):\n",
    "        super(GeneratorBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.style1 = nn.Linear(style_dim, out_channels * 2)\n",
    "        self.style2 = nn.Linear(style_dim, out_channels * 2)\n",
    "        self.noise1 = nn.Parameter(torch.randn(1, out_channels * 2 , 1, 1))\n",
    "        self.noise2 = nn.Parameter(torch.randn(1, out_channels , 1, 1))\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "    def forward(self, x, style):\n",
    "        x = self.upsample(x)\n",
    "        noise = torch.randn(x.size(0), 1, x.size(2), x.size(3), device=device)  # Noise for first layer\n",
    "        style1 = self.style1(style)\n",
    "        # print(\"x.shape: \", x.shape)\n",
    "        # print(\"noise.shape: \", noise.shape)\n",
    "        # print(\"self.noise1.shape: \",self.noise1.shape)  #!!!\n",
    "        # print(\"style1.shape: \", style1.shape)\n",
    "        x = adain(F.leaky_relu(self.conv1(x + self.noise1 * noise), 0.2), style1)\n",
    "\n",
    "        noise = torch.randn(x.size(0), 1, x.size(2), x.size(3), device=device)  # Noise for second layer\n",
    "        style2 = self.style2(style)\n",
    "        # print(\"x.shape: \", x.shape)\n",
    "        # print(\"noise.shape: \", noise.shape)\n",
    "        # print(\"self.noise2.shape: \",self.noise2.shape)  #!!!\n",
    "        # print(\"style2.shape: \", style2.shape)\n",
    "        x = adain(F.leaky_relu(self.conv2(x + self.noise2 * noise), 0.2), style2)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# StyleGAN Discriminator\n",
    "# ------------------------------\n",
    "class StyleGANDiscriminator(nn.Module):\n",
    "    def __init__(self, img_channels, base_channels):\n",
    "        super(StyleGANDiscriminator, self).__init__()\n",
    "\n",
    "        # Progressive blocks\n",
    "        self.prog_blocks = nn.ModuleList([\n",
    "            DiscriminatorBlock(base_channels // (2**i), base_channels // (2**(i + 1)))\n",
    "            for i in range(4)  # For 64x64 -> 32x32 -> 16x16 -> 8x8 -> 4x4\n",
    "        ])\n",
    "\n",
    "        # From RGB conversion layer\n",
    "        self.from_rgb = nn.Conv2d(img_channels, base_channels, kernel_size=1)\n",
    "\n",
    "        # Final layer\n",
    "        self.final_conv = nn.Conv2d(base_channels // (2**4), 1, kernel_size=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.from_rgb(x)\n",
    "        for block in self.prog_blocks:\n",
    "            x = block(x)\n",
    "        x = self.final_conv(x)\n",
    "        return x.view(x.size(0))  # Flatten to [batch_size]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Discriminator Block\n",
    "# ------------------------------\n",
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DiscriminatorBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.downsample = nn.AvgPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        x = F.leaky_relu(self.conv2(x), 0.2)\n",
    "        x = self.downsample(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1-Adversarial Loss: Use Wasserstein Loss with Gradient Penalty for stability\n",
    "2-Gradient Penalty: Penalize gradients of the discriminator to enforce Lipschitz continuity\n",
    "\"\"\"\n",
    "\n",
    "def gradient_penalty(D, real_images, fake_images, device):\n",
    "    batch_size, C, H, W = real_images.size()\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1, device=device)\n",
    "    interpolated = epsilon * real_images + (1 - epsilon) * fake_images\n",
    "    interpolated.requires_grad_(True)\n",
    "    interpolated_score = D(interpolated)\n",
    "    grad_outputs = torch.ones_like(interpolated_score, device=device)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=interpolated_score,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_norm = gradients.norm(2, dim=1)\n",
    "    return ((gradient_norm - 1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"R1 Regularization instead of Gradient Penalty\"\"\"\n",
    "def r1_regularization(real_images,real_scores,device):\n",
    "    real_images.requires_grad_(True)\n",
    "    grad_outputs=torch.ones_like(real_scores, device=device)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=real_scores,\n",
    "        inputs=real_images,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(real_images.size(0), -1)\n",
    "    return (gradients.norm(2, dim=1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = 'generated'\n",
    "os.makedirs(sample_dir, exist_ok = True)\n",
    "\n",
    "def save_images(images,index, show = True):\n",
    "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
    "    save_image(denorm(images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
    "    print('Saving', fake_fname)\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "        ax.set_xticks([]), ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images.cpu().detach(), nrow=8).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Loop\n",
    "\n",
    "def train_stylegan(generator, discriminator, dataloader, epochs, latent_dim, device):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    g_loss_history = []\n",
    "    d_loss_history = []\n",
    "    real_scores_history = []\n",
    "    fake_scores_history = []\n",
    "\n",
    "    # Optimizers\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(), lr=5e-4, betas=(0.0, 0.99))\n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=5e-4, betas=(0.0, 0.99))\n",
    "\n",
    "    # Loss weights\n",
    "    gradient_penalty_weight = 10.0\n",
    "    r1_penalty_weight = 10.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for real_images, _ in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            #Adding noise to obtain stochastic features\n",
    "            #real_images = real_images + torch.randn_like(real_images) * 0.05\n",
    "            real_images = real_images.to(device)\n",
    "            real_images.requires_grad_(True)\n",
    "            # ------------------------------\n",
    "            # Train Discriminator\n",
    "            # ------------------------------\n",
    "            z = torch.randn(real_images.size(0), latent_dim, device=device)\n",
    "            fake_images = generator(z)\n",
    "\n",
    "            #Adding noise to obtain stochastic features\n",
    "            #fake_images = fake_images + torch.randn_like(fake_images) * 0.05 \n",
    "\n",
    "            real_scores = discriminator(real_images)\n",
    "            fake_scores = discriminator(fake_images.detach())\n",
    "\n",
    "            #gp = gradient_penalty(discriminator, real_images, fake_images, device)\n",
    "            #d_loss = (-1.0) * real_scores.mean() + fake_scores.mean() + gradient_penalty_weight * gp\n",
    "\n",
    "            r1 = r1_regularization(real_images, real_scores, device)\n",
    "            d_loss = (-1.0) * real_scores.mean() + fake_scores.mean() + r1_penalty_weight/2 * r1\n",
    "\n",
    "            #print(\"Discriminator - r1: \", r1, \" real_scores.mean(): \", real_scores.mean(), \" fake_scores.mean(): \", fake_scores.mean(), \" d_loss: \", d_loss) #!!!\n",
    "\n",
    "            d_optimizer.zero_grad()\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # ------------------------------\n",
    "            # Train Generator\n",
    "            # ------------------------------\n",
    "            z = torch.randn(real_images.size(0), latent_dim, device=device)\n",
    "            fake_images = generator(z)\n",
    "\n",
    "\n",
    "            #Adding noise to obtain stochastic features\n",
    "            #fake_images = fake_images + torch.randn_like(fake_images) * 0.05\n",
    "\n",
    "            fake_scores = discriminator(fake_images)\n",
    "\n",
    "            g_loss = (-1.0) * fake_scores.mean()\n",
    "\n",
    "            #print(\"Generator - g_loss: \", g_loss)   #!!!\n",
    "\n",
    "            g_optimizer.zero_grad()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "\n",
    "        #Record losses & scores\n",
    "        g_loss_history.append(g_loss)\n",
    "        d_loss_history.append(d_loss)\n",
    "        real_scores_history.append(real_scores.mean())\n",
    "        fake_scores_history.append(fake_scores.mean())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
    "        print(\"r1: \", r1.item(), \" real_scores.mean(): \", real_scores.mean().item(), \" fake_scores.mean(): \", fake_scores.mean().item())\n",
    "\n",
    "        # Save generated images\n",
    "        save_images(fake_images, epoch, show=False)\n",
    "    \n",
    "    return g_loss_history, d_loss_history, real_scores_history, fake_scores_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "latent_dim = 512\n",
    "img_channels = 3\n",
    "base_channels = 512\n",
    "epochs = 150\n",
    "\n",
    "generator = StyleGANGenerator(latent_dim, img_channels, base_channels).to(device)\n",
    "discriminator = StyleGANDiscriminator(img_channels, base_channels).to(device)\n",
    "\n",
    "# Train\n",
    "history = train_stylegan(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    dataloader=train_dl,\n",
    "    epochs=epochs,\n",
    "    latent_dim=latent_dim,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses = history[0]\n",
    "g_losses = history[1]\n",
    "\n",
    "d_losses = [tensor.detach().cpu().numpy() for tensor in d_losses]\n",
    "g_losses = [tensor.detach().cpu().numpy() for tensor in g_losses]\n",
    "\n",
    "plt.plot(d_losses,'-')\n",
    "plt.plot(g_losses,'-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Discriminator','Generator'])\n",
    "plt.title('Losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_scores_mean = history[2]\n",
    "fake_scores_mean = history[3]\n",
    "\n",
    "real_scores_mean = [tensor.detach().cpu().numpy() for tensor in real_scores_mean]\n",
    "fake_scores_mean = [tensor.detach().cpu().numpy() for tensor in fake_scores_mean]\n",
    "\n",
    "plt.plot(real_scores_mean,'-')\n",
    "plt.plot(fake_scores_mean,'-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('lscore')\n",
    "plt.legend(['Real','Fake'])\n",
    "plt.title('Scores')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generator and discriminator state dictionaries\n",
    "torch.save(generator.state_dict(), \"generator.pth\")\n",
    "torch.save(discriminator.state_dict(), \"discriminator.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved models\n",
    "\n",
    "# Initialize models\n",
    "latent_dim = 512\n",
    "img_channels = 3\n",
    "base_channels = 512\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "generator = StyleGANGenerator(latent_dim, img_channels, base_channels).to(device)\n",
    "discriminator = StyleGANDiscriminator(img_channels, base_channels).to(device)\n",
    "\n",
    "# Load the state dictionaries\n",
    "generator.load_state_dict(torch.load(\"generator.pth\"))\n",
    "discriminator.load_state_dict(torch.load(\"discriminator.pth\"))\n",
    "\n",
    "# Ensure the models are in evaluation mode (optional for inference)\n",
    "generator.eval()\n",
    "discriminator.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an image using generator of Style GAN\n",
    "\n",
    "#Create latent input (gaussian noise image)\n",
    "z = torch.randn(64, latent_dim, device=device)\n",
    "#Create fake image \n",
    "fake_image = generator(z)\n",
    "\n",
    "show_images(fake_image.to(\"cpu\"), nmax=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
